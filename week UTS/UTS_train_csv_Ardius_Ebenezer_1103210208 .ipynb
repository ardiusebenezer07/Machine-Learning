{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoparAwayyy/Machine-Learning/blob/main/UTS/UTS_Dwi_Saputra_Sopar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAMA  : ARDIUS EBENEZER SIMANJUNTAK\n",
        "\n",
        "NIM   : 1103210220\n",
        "\n",
        "dataset : https://www.kaggle.com/datasets/parisrohan/credit-score-classification\n",
        "\n",
        "promp pt : https://chat.openai.com/c/f6079e8e-42c1-4a4b-b1a7-c56773552fa1\n",
        "\n",
        "Referensi\n",
        "https://www.kaggle.com/code/yeremiamarcelliust/oversampling-rf-decision-tree-svc-credit-s\n"
      ],
      "metadata": {
        "id": "1AjbxZUfES6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library yang digunakan"
      ],
      "metadata": {
        "id": "z6yuOZYrHrW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "MzCV4d1wpbsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mengconectkan ke drive"
      ],
      "metadata": {
        "id": "sftGpSRXHydK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qj3kpK_h5FVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths\n",
        "train_file_path = '/content/drive/MyDrive/train.csv'\n",
        "\n",
        "# Load datasets\n",
        "train_data = pd.read_csv(train_file_path)"
      ],
      "metadata": {
        "id": "bnM7uk4r5QQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "S7vXJBCruH5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "EhRHmn4PuFuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-processing**"
      ],
      "metadata": {
        "id": "XBOt34ir_PaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "train_data = train_data.drop(columns=['ID',\"Customer_ID\",\"SSN\",\"Credit_History_Age\",'Name',\"Type_of_Loan\"])\n",
        "train_data = train_data.dropna(axis=0)\n",
        "\n",
        "train_data = train_data.applymap(lambda x: x.replace('_', '') if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "e0OVergrp1b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "id": "RDuoEv4JuDJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = ['Month',\"Occupation\",\"Credit_Mix\",\"Payment_of_Min_Amount\",\"Payment_Behaviour\",\"Credit_Score\"]\n",
        "label_encoder = LabelEncoder()\n",
        "for x in categorical:\n",
        "    train_data[x] = label_encoder.fit_transform(train_data[x])"
      ],
      "metadata": {
        "id": "qJBda--UqJva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membersihkan data"
      ],
      "metadata": {
        "id": "-VgK4hfxFdgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saring nilai negatif dalam kolom numerik\n",
        "train_data = train_data.apply(pd.to_numeric,errors='coerce')\n",
        "train_data = train_data.applymap(lambda x: x if x >= 0 else None)\n",
        "train_data.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "WKlnv4Feqbuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hitung kuartil untuk setiap feature\n",
        "quartiles = train_data.quantile([0.25, 0.75])\n",
        "\n",
        "# Hitung Rentang Interkuartil (IQR) untuk setiap feature\n",
        "IQR = quartiles.loc[0.75] - quartiles.loc[0.25]\n",
        "\n",
        "# Tentukan batas bawah dan atas untuk setiap feature\n",
        "lower_bound = (quartiles.loc[0.25] - 1.5 * IQR).to_dict()\n",
        "upper_bound = (quartiles.loc[0.75] + 1.5 * IQR).to_dict()\n",
        "\n",
        "# Filter data yang berada di luar batas untuk setiap feature\n",
        "filtered_data = train_data.copy()\n",
        "for feature in train_data.columns:\n",
        "    lower_bound_value = lower_bound[feature]\n",
        "    upper_bound_value = upper_bound[feature]\n",
        "    filtered_data = filtered_data[(filtered_data[feature] >= lower_bound_value) & (filtered_data[feature] <= upper_bound_value)]\n",
        "train_data = filtered_data"
      ],
      "metadata": {
        "id": "-y06P_DRqhlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST MODEL**"
      ],
      "metadata": {
        "id": "mqcUyFox_Ip-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Decision Tree**\n",
        "\n",
        "memiliki akurasi 68,7%"
      ],
      "metadata": {
        "id": "ZkARipYR8PJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = train_data.drop('Credit_Score', axis=1)\n",
        "y = train_data['Credit_Score']\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Penskalaan fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Inisialisasi pengklasifikasi Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Melatih pengklasifikasi Decision Tree\n",
        "dt_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Memprediksi label untuk set pengujian\n",
        "y_pred = dt_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "akurasi = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", akurasi)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Menghitung mean absolute error\n",
        "mean_error = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mean_error)\n",
        "\n",
        "# Menghitung mean absolute percentage error (MAPE)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "\n",
        "# Menghitung mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "id": "yWV_1Ni5LoyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Random Forest**\n",
        "\n",
        "Memiliki akurasi 79,5%"
      ],
      "metadata": {
        "id": "-yB5MUm98ChE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = train_data.drop('Credit_Score', axis=1)\n",
        "y = train_data['Credit_Score']\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Penskalaan fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Inisialisasi pengklasifikasi Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Melatih pengklasifikasi Random Forest\n",
        "rf_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Memprediksi label untuk set pengujian\n",
        "y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "akurasi = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", akurasi)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Menghitung mean absolute error\n",
        "mean_error = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mean_error)\n",
        "\n",
        "# Menghitung mean absolute percentage error (MAPE)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "\n",
        "# Menghitung mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "id": "7JkQssxSq4s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL SVM**\n",
        "\n",
        "Memiliki akurasi 72,9%"
      ],
      "metadata": {
        "id": "C-6R6nkW78DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = train_data.drop('Credit_Score', axis=1)\n",
        "y = train_data['Credit_Score']\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Penskalaan fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Inisialisasi pengklasifikasi SVM\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Melatih pengklasifikasi SVM\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Memprediksi label untuk set pengujian\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "akurasi = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", akurasi)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Menghitung mean absolute error\n",
        "mean_error = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mean_error)\n",
        "\n",
        "# Menghitung mean absolute percentage error (MAPE)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "\n",
        "# Menghitung mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "id": "X6--IV3HrXCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Model Implementation, Hyperparameter Tuning, and Evaluation\n",
        "\n",
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = train_data.drop('Credit_Score', axis=1)\n",
        "y = train_data['Credit_Score']\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "def evaluate_tuned_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n=== {model_name} Results ===\")\n",
        "    print(f\"Best Parameters: {model.best_params_}\")\n",
        "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\"R2 Score: {r2:.4f}\")\n",
        "    print(f\"Best Cross-validation Score: {model.best_score_:.4f}\")\n",
        "\n",
        "    # Plotting actual vs predicted values\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title(f'{model_name}: Actual vs Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return mse, r2, model.best_score_\n",
        "\n",
        "# Polynomial Regression with Pipeline and Tuning\n",
        "poly_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "poly_params = {\n",
        "    'poly__degree': [1, 2, 3]\n",
        "}\n",
        "\n",
        "poly_grid = GridSearchCV(\n",
        "    poly_pipeline,\n",
        "    poly_params,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "poly_grid.fit(X_train, y_train)\n",
        "poly_metrics = evaluate_tuned_model(poly_grid, X_train, X_test, y_train, y_test, \"Polynomial Regression\")"
      ],
      "metadata": {
        "id": "sOVHclrvdkDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-NN Regression with Tuning\n",
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', KNeighborsRegressor())\n",
        "])\n",
        "\n",
        "knn_params = {\n",
        "    'regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'regressor__weights': ['uniform', 'distance'],\n",
        "    'regressor__p': [1, 2]  # Manhattan or Euclidean distance\n",
        "}\n",
        "\n",
        "knn_grid = GridSearchCV(\n",
        "    knn_pipeline,\n",
        "    knn_params,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "knn_grid.fit(X_train, y_train)\n",
        "knn_metrics = evaluate_tuned_model(knn_grid, X_train, X_test, y_train, y_test, \"k-NN Regression\")\n"
      ],
      "metadata": {
        "id": "klHjGBgRna3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Regression with Tuning\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', XGBRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "xgb_params = {\n",
        "    'regressor__n_estimators': [100, 200],\n",
        "    'regressor__max_depth': [3, 5, 7],\n",
        "    'regressor__learning_rate': [0.01, 0.1],\n",
        "    'regressor__subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "xgb_grid = GridSearchCV(\n",
        "    xgb_pipeline,\n",
        "    xgb_params,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "xgb_metrics = evaluate_tuned_model(xgb_grid, X_train, X_test, y_train, y_test, \"XGBoost Regression\")\n"
      ],
      "metadata": {
        "id": "ZuWeMTdlnasP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model XGBOOST**\n",
        "\n",
        "Memiliki akurasi 77,8%"
      ],
      "metadata": {
        "id": "d5QtaRlw7u1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = train_data.drop('Credit_Score', axis=1)\n",
        "y = train_data['Credit_Score']\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Penskalaan fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Inisialisasi pengklasifikasi XGBoost\n",
        "xgb_classifier = XGBClassifier()\n",
        "\n",
        "# Melatih pengklasifikasi XGBoost\n",
        "xgb_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Memprediksi label untuk set pengujian\n",
        "y_pred = xgb_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "akurasi = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", akurasi)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Menghitung mean absolute error\n",
        "mean_error = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mean_error)\n",
        "\n",
        "# Menghitung mean absolute percentage error (MAPE)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "\n",
        "# Menghitung mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "id": "VKOqg13z7mKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model performances\n",
        "models = ['Polynomial', 'Decision Tree', 'k-NN', 'XGBoost']\n",
        "mse_scores = [poly_metrics[0], dt_metrics[0], knn_metrics[0], xgb_metrics[0]]\n",
        "r2_scores = [poly_metrics[1], dt_metrics[1], knn_metrics[1], xgb_metrics[1]]\n",
        "cv_scores = [poly_metrics[2], dt_metrics[2], knn_metrics[2], xgb_metrics[2]]\n",
        "\n",
        "# Plot comparison\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(models, mse_scores)\n",
        "plt.title('MSE Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Mean Squared Error')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.bar(models, r2_scores)\n",
        "plt.title('R² Score Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('R² Score')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(models, cv_scores)\n",
        "plt.title('Cross-validation Score Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('CV Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for XGBoost\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': xgb_grid.best_estimator_.named_steps['regressor'].feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
        "plt.title('Feature Importance (XGBoost)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fRibNYuBp_NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pk6q0mkVp-zP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}