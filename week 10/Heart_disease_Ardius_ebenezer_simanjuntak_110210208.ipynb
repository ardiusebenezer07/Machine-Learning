{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nFvp6t1pSLYe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed untuk reproduksibilitas\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "sCXHRkUtSYhO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **Memuat dataset**\n",
        "file_path = '/content/heart.csv' # Sesuaikan path jika tidak menggunakan Colab\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "5bCcC07pfIRe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat dummy data penyakit jantung\n",
        "def generate_heart_disease_data(n_samples=1000):\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Fitur-fitur yang mungkin mempengaruhi penyakit jantung\n",
        "    age = np.random.normal(55, 10, n_samples)\n",
        "    cholesterol = np.random.normal(200, 50, n_samples)\n",
        "    blood_pressure = np.random.normal(130, 20, n_samples)\n",
        "    max_heart_rate = np.random.normal(150, 30, n_samples)\n",
        "\n",
        "    # Membuat target berdasarkan kombinasi fitur\n",
        "    risk_score = (\n",
        "        0.3 * age +\n",
        "        0.2 * cholesterol +\n",
        "        0.2 * blood_pressure -\n",
        "        0.1 * max_heart_rate\n",
        "    )\n",
        "\n",
        "    # Klasifikasi binary: 1 (berisiko), 0 (tidak berisiko)\n",
        "    labels = (risk_score > np.median(risk_score)).astype(int)\n",
        "\n",
        "    # Membuat DataFrame\n",
        "    data = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'cholesterol': cholesterol,\n",
        "        'blood_pressure': blood_pressure,\n",
        "        'max_heart_rate': max_heart_rate,\n",
        "        'heart_disease': labels\n",
        "    })\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "fcNy858lSYeZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persiapan data\n",
        "data = generate_heart_disease_data()"
      ],
      "metadata": {
        "id": "fSbSjheVSYbK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "X = data.drop('heart_disease', axis=1)\n",
        "y = data['heart_disease']"
      ],
      "metadata": {
        "id": "yOJa5LqZWBpu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "A_72CVPzWBj0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "el9J6xJgXdW4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi ke tensor PyTorch\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train.values).unsqueeze(1)\n",
        "y_test = torch.FloatTensor(y_test.values).unsqueeze(1)"
      ],
      "metadata": {
        "id": "fTLvIbXwXdLh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisi Model MLP dengan berbagai konfigurasi\n",
        "class HeartDiseaseClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons, activation='relu'):\n",
        "        super(HeartDiseaseClassifier, self).__init__()\n",
        "\n",
        "        # Pilih activation function\n",
        "        if activation == 'linear':\n",
        "            act_func = nn.Identity()\n",
        "        elif activation == 'sigmoid':\n",
        "            act_func = nn.Sigmoid()\n",
        "        elif activation == 'relu':\n",
        "            act_func = nn.ReLU()\n",
        "        elif activation == 'tanh':\n",
        "            act_func = nn.Tanh()\n",
        "        elif activation == 'softmax':\n",
        "            act_func = nn.Softmax(dim=1)\n",
        "\n",
        "        # Bangun layer-layer\n",
        "        layers = []\n",
        "        prev_neurons = input_size\n",
        "\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(prev_neurons, neurons))\n",
        "            layers.append(act_func)\n",
        "            prev_neurons = neurons\n",
        "\n",
        "        layers.append(nn.Linear(prev_neurons, 1))\n",
        "        layers.append(nn.Sigmoid())  # Output biner\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "6AokarkgXqMl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Training\n",
        "def train_model(model, X_train, y_train, X_test, y_test,\n",
        "                epochs, learning_rate, batch_size):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "# Evaluasi\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test)\n",
        "        predicted = (test_outputs > 0.5).float()\n",
        "        accuracy = (predicted == y_test).float().mean()\n",
        "\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "id": "h0NpaKVPXqCD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search Parameter\n",
        "params = {\n",
        "    'hidden_layers': [1, 2, 3],\n",
        "    'neurons': [4, 8, 16, 32, 64],\n",
        "    'activation': ['linear', 'sigmoid', 'relu', 'tanh', 'softmax'],\n",
        "    'epochs': [1, 10, 25, 50, 100, 250],\n",
        "    'learning_rate': [1.0, 0.1, 0.01, 0.001, 0.0001],\n",
        "    'batch_size': [16, 32, 64, 128, 256, 512]\n",
        "}"
      ],
      "metadata": {
        "id": "8r_AdXfmXvCQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menjalankan grid search\n",
        "def grid_search(X_train, y_train, X_test, y_test):\n",
        "    input_size = X_train.shape[1]\n",
        "    results = []\n",
        "\n",
        "    # Kombinasi parameter terbatas untuk efisiensi\n",
        "    param_combinations = list(itertools.product(\n",
        "        params['hidden_layers'][:2],  # Batasi kombinasi\n",
        "        params['neurons'][:3],\n",
        "        params['activation'][:3],\n",
        "        params['epochs'][:3],\n",
        "        params['learning_rate'][:3],\n",
        "        params['batch_size'][:3]\n",
        "    ))\n",
        "\n",
        "    for config in param_combinations:\n",
        "        hl, neurons, act, epochs, lr, bs = config\n",
        "\n",
        "        model = HeartDiseaseClassifier(\n",
        "            input_size,\n",
        "            hidden_layers=hl,\n",
        "            neurons=neurons,\n",
        "            activation=act\n",
        "        )\n",
        "\n",
        "        accuracy = train_model(\n",
        "            model, X_train, y_train,\n",
        "            X_test, y_test,\n",
        "            epochs=epochs,\n",
        "            learning_rate=lr,\n",
        "            batch_size=bs\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'Hidden Layers': hl,\n",
        "            'Neurons': neurons,\n",
        "            'Activation': act,\n",
        "            'Epochs': epochs,\n",
        "            'Learning Rate': lr,\n",
        "            'Batch Size': bs,\n",
        "            'Accuracy': accuracy\n",
        "        })"
      ],
      "metadata": {
        "id": "iqVy_wPJadF5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan hasil\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values('Accuracy', ascending=False)\n",
        "    print(results_df.head(10))\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "tl0aD50Qac8V",
        "outputId": "7e2a3aec-1be8-45b5-f74f-1b87ac197c29"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-29-316f2442ccdb>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-316f2442ccdb>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    results_df = pd.DataFrame(results)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan Grid Search\n",
        "results = grid_search(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "0AdEI6f2ak1B"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}